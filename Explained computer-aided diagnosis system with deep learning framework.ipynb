{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf4e3fe",
   "metadata": {},
   "source": [
    "<h1>Explained computer-aided Diagnosis system with deep learning framework</h1>\n",
    "<p>The aim of this project is to create a python implementation of a computer aided diagnostic system that upon providing a result will explain the reasoning behind the result to promote transparency and make understanding the result much more understandable for medical staff</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2abf6",
   "metadata": {},
   "source": [
    "before we begin firstly we need to initialise our working area by first installing shap,pytorch and importing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install shap\n",
    "%pip install lime\n",
    "%pip install torch \n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from lime import lime_tabular \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c294e",
   "metadata": {},
   "source": [
    "The necessary libraries have been installed and imported for data processing, data representation and mathematics, however we still need to load the data and clean it before we can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('multiple sclerosis dataset.csv')\n",
    "\n",
    "# Remove rows with missing values \n",
    "#data = data.dropna()\n",
    "\n",
    "# Alternatively we can use the average of the column to fill in missing values\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "# Select only numerical columns for analysis as our data is provided in numerical format\n",
    "data = data.select_dtypes(include=[np.number])\n",
    "data = data.drop(columns=['Unnamed: 0'])  # Drop non-informative columns\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.columns.tolist())\n",
    "print(data.shape)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4504f0",
   "metadata": {},
   "source": [
    "<p>The data classifications are:</p>\n",
    "<ul>\n",
    "<li>Age: Age of the patient (in years)</li>\n",
    "<li>Schooling: time the patient spent in school (in years)</li>\n",
    "<li>Gender: 1=male, 2=female</li>\n",
    "<li>Breastfeeding: 1=yes, 2=no, 3=unknown</li>\n",
    "<li>Varicella: 1=positive, 2=negative, 3=unknown</li>\n",
    "<li>Initial_Symptoms: 1=visual, 2=sensory, 3=motor, 4=other, 5= visual and sensory, 6=visual and motor, 7=visual and others, 8=sensory and motor, 9=sensory and other, </li>\n",
    "<li>10=motor and other, 11=Visual, sensory and motor, 12=visual, sensory and other, 13=Visual, motor and other, 14=Sensory, motor and other, 15=visual,sensory,motor and other</li>\n",
    "<li>Mono _or_Polysymptomatic: 1=monosymptomatic, 2=polysymptomatic, 3=unknown</li>\n",
    "<li>Oligoclonal_Bands: 0=negative, 1=positive, 2=unknown</li>\n",
    "<li>LLSSEP: 0=negative, 1=positive</li>\n",
    "<li>ULSSEP:0=negative, 1=positive</li>\n",
    "<li>VEP:0=negative, 1=positive</li>\n",
    "<li>BAEP: 0=negative, 1=positive</li>\n",
    "<li>Periventricular_MRI:0=negative, 1=positive</li>\n",
    "<li>Cortical_MRI: 0=negative, 1=positive</li>\n",
    "<li>Infratentorial_MRI:0=negative, 1=positive</li>\n",
    "<li>Spinal_Cord_MRI: 0=negative, 1=positive</li>\n",
    "<li>initial_EDSS:?</li>\n",
    "<li>final_EDSS:?</li>\n",
    "<li>Group: 1=CDMS (definitive MS), 2=non-CDMS </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78993ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop('group', axis=1)\n",
    "y = data['group']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors for inputs\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "# Initialize the neural network, loss function and optimizer\n",
    "model = SimpleNN(input_size=18, hidden_size=60, output_size=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the neural network\n",
    "epochs = 343\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    preds = torch.argmax(model(X_test), dim=1)\n",
    "    acc = (preds == y_test).sum().item() / len(y_test)\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "model.cpu()\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0592349",
   "metadata": {},
   "source": [
    "The model can now be used to predict whether or not a person in our data has MS, but a prediction isn't reliable without explanation so shap and lime explanations will be implemented to explain the results of the overall set of predictions and a random instance of a prediction in the dataset, for both a local (LIME) and global (SHAP) representation of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples for explanation\n",
    "X_train_sample = X_train[:50]\n",
    "X_test_sample = X_test[:10]\n",
    "\n",
    "#classifier function for SHAP and LIME \n",
    "classifier_fn = lambda x: torch.softmax(\n",
    "    model(torch.tensor(x, dtype=torch.float32)), dim=1\n",
    ").detach().numpy()\n",
    "\n",
    "exp_shap = shap.DeepExplainer(model, X_train_sample)\n",
    "shap_values = exp_shap.shap_values(X_test_sample)\n",
    "\n",
    "\n",
    "lime_instance = random.randint(0, X_test_sample.shape[0]-1)\n",
    "\n",
    "exp_lime = lime_tabular.LimeTabularExplainer(X_train_sample.numpy(), feature_names=feature_names, class_names=le.classes_, discretize_continuous=True)\n",
    "\n",
    "exp_lime = exp_lime.explain_instance(\n",
    "    X_test_sample[lime_instance].numpy(), predict_fn=classifier_fn, num_features=6)\n",
    "\n",
    "lime_output = exp_lime.as_html(show_table=True)\n",
    "\n",
    "# SHAP summary plot display\n",
    "display(HTML(\n",
    "    f\"\"\"<h2>SHAP Summary Plot</h2>\"\"\"))\n",
    "shap.summary_plot(shap_values, X_test_sample.numpy(), feature_names=feature_names)\n",
    "\n",
    "#lime explanation display (formatted because else it displays as black on dark background)\n",
    "lime_prediction = le.classes_[np.argmax(classifier_fn(X_test_sample[lime_instance].numpy().reshape(1, -1)))]\n",
    "display(HTML(\n",
    "    f\"\"\"\n",
    "    <h2>LIME Explanation for Instance {lime_instance}</h2>\n",
    "    <div style=\"background-color: white;padding: 10px; \">\n",
    "    {lime_output}\n",
    "    <h2 style=\"color:{'lightgreen' if lime_prediction == 2 else 'red'};\"> The model predicted that the patient: {'has definitive Multiple Sclerosis' if lime_prediction == 1 else 'does not have Multiple Sclerosis'} </h2>\n",
    "</div>\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
